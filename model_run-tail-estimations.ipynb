{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "incorrect-footage",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, csv, subprocess\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "raising-familiar",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_unique_areas(areas):\n",
    "    uniques, counts = np.unique(areas, return_counts = True)\n",
    "    counts = counts.astype(str)\n",
    "    area_list = []\n",
    "    count_list = []\n",
    "    area_list.append(uniques)\n",
    "    count_list.append(counts)\n",
    "    return np.vstack((area_list, count_list)).T "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "understanding-arena",
   "metadata": {},
   "source": [
    "### Voitalov et al. (2019) published a python script to identify power law distributions. This notebook automates the steps needed to check the distributions produced by the model simulations. \n",
    "\n",
    "#### Please refer to Voitalov et al. (2019) for more detail on identifying power laws:\n",
    "#### Voitalov, I., Van Der Hoorn, P., Van Der Hofstad, R., & Krioukov, D. (2019). Scale-free networks well done. Physical Review Research, 1(3). https://doi.org/10.1103/PhysRevResearch.1.033034\n",
    "\n",
    "#### See https://github.com/ivanvoitalov/tail-estimation for step-by-step instructions on using their tail-estimation script. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "urban-client",
   "metadata": {},
   "source": [
    "#### The script below combines the output from each simulation for a given set of parameters into a .dat file. It repeats the process for each parameter set to produce 32 .dat files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "advised-plant",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = \"model-data/csv-files\" #path to directory of simulation CSVs\n",
    "\n",
    "#Go through each sub-directory\n",
    "for d1 in os.listdir(d):\n",
    "    if not d1.startswith('.'):  #ignore hidden files  \n",
    "        x=os.path.join(d,d1)\n",
    "        for d2 in os.listdir(x):\n",
    "            if not d2.startswith('.'):\n",
    "                y=os.path.join(x,d2)\n",
    "                for d3 in os.listdir(y):\n",
    "                    z = os.path.join(y, d3)\n",
    "                    if not d3.startswith('.'):\n",
    "                        #Append the area column from the final simulation timestep\n",
    "                        areasList = []\n",
    "                        i = 0\n",
    "                        for f in os.listdir(z):\n",
    "                            if i == 0: \n",
    "                                fullname = os.path.splitext(f)[0][:-2] #take the name from the first simulation file\n",
    "                            df = pd.read_csv(os.path.join(z, f))\n",
    "                            last_step = df.iloc[:,-1]\n",
    "                            areasList.append(last_step.iloc[:])\n",
    "                            i += 1\n",
    "                        areasList = np.array(areasList)\n",
    "                        areasList = areasList[~np.isnan(areasList)]\n",
    "                        count = find_unique_areas(areasList)\n",
    "\n",
    "                        simname = '_' + fullname + '_combined'\n",
    "\n",
    "                        #Write the combined list of areas and counts to a .dat file\n",
    "                        fname = os.path.join(\"model-data/combined-dat-files\", simname + '.dat')\n",
    "                        with open(fname, 'w', newline = '') as datfile:\n",
    "                            writer = csv.writer(datfile, delimiter = ' ')\n",
    "                            for i in range(len(count)):\n",
    "                                writer.writerow(count[i,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electric-definition",
   "metadata": {},
   "source": [
    "#### Now run \"voitalov-tail-estimation.py\" on each of the simulation .dat files. Alternatively, you can open a terminal and run the script on individual .dat files. See https://github.com/ivanvoitalov/tail-estimation for more information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legitimate-labor",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Does not run on mac, check to see if it runs on PC\n",
    "for f in os.listdir(\"model-data/combined-dat-files/\"):\n",
    "    if not f.startswith('.'):\n",
    "        if f.endswith('.dat'):\n",
    "            n = os.path.splitext(f)[0]\n",
    "            if os.path.isfile(n + '.pdf') == False:\n",
    "                subprocess.call(['python', 'voitalov-tail-estimation.py', os.path.join(\"model-data/combined-dat-files/\",f), n + '_new.pdf'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
